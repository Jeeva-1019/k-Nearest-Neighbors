This project demonstrates a from-scratch implementation of the k-Nearest Neighbors (k-NN) classification algorithm using NumPy, along with performance evaluation and comparison against scikit-learn’s KNeighborsClassifier.
The goal of this project is to deeply understand the core mechanics of k-NN, including distance calculation, neighbor selection, and majority voting, rather than relying on high-level libraries.
Synthetic dataset with 200 samples and 5 numerical features
Custom k-NN classifier implemented from scratch
Euclidean distance–based neighbor selection
Majority voting for classification
Model evaluation using accuracy, precision, and recall
Comparison with scikit-learn implementation
Visualization of decision boundary using 2 features
